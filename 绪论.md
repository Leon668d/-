# -
我的小白机器学习空间
一、绪论
	1. 引言
	2. 基本术语
		a. 数据集
		b. 示例、样本
			i. 关于一个事件或对象的描述
			ii. 特征向量
		c. 属性、特征
			i. 反映事件或对象在某方面的表现或性质的事项
		d. 属性值
		e. 属性空间、样本空间、输入空间
			i. 属性张成的空间
		f. 训练数据
			i. 训练过程中使用的数据
			ii. 训练样本
				1) 训练中使用的样本
			iii. 训练集
				1) 训练样本组成的集合
		g. 假设、真相、真实（ground-truth)
			i. 学得模型对应了关于数据的某种潜在规律
		h. 标记
			i. 关于示例结果的信息（好瓜）
		i. 样例
			i. 拥有了标记信息的示例
		j. 输出空间、标记空间
			i. 所有标记的集合
		k. 学习模型
			i. 分类(classification)
				1) 预测离散值
				2) 二分类——“正类”、“反类”
			ii. 回归(regression)
				1) 预测连续值
		l. 测试
			i. 学得模型后，使用其进行预测的过程
			ii. 测试样本
				1) 被预测的样本
		m. 聚类
			i. 将训练集中的样本分为若干组（有潜在的概念划分）
		n. 学习任务分类
			i. 监督学习（supervised learning)
				1) 分类和回归
			ii. 无监督学习(unsupervised learning)
				1) 聚类
		o. 泛化
			i. 学得模型适用于新样本的能力
	3. 假设空间
		a. 归纳学习——从样例中学习
			i. 概念学习
				1) 布尔概念学习（是、不是）
			ii. 过程
				1) 一个在所有假设组成的空间中进行搜索的过程，
				搜索目标是找到与训练集“匹配”的假设,即能够
				将训练集中的瓜判断正确的假设
				
		b. 版本空间
			i. 与训练集一致的假设空间
	4. 归纳偏好
		——ml算法在学习过程中对某种类型假设的偏好
		a. 奥卡姆剃刀（Occam's razor)原则
			i. ”若有多个假设与观察一致，则选择最简单的那个“
				1) 如采用“更平滑的曲线”
		b. 没有免费的午餐定理（NFL定理）
			i. 不同学习算法具有相同的期望性能（总误差）
前提：所有“问题”出现的机会相同（同等重要）![image](https://github.com/Leon668d/-/assets/130523488/953b8e6e-8cd3-4187-ab21-f53292881b93)
